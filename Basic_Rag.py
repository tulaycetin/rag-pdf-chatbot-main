# -------------------------------
#  RAG TabanlÄ± PDF Analiz ve Sohbet Botu
# -------------------------------
import os
import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.docstore.document import Document
from dotenv import load_dotenv

# -------------------------------
# âš™ï¸ Streamlit Sayfa YapÄ±landÄ±rmasÄ± (HER ZAMAN EN BAÅTA OLMALI!)
# -------------------------------
st.set_page_config(page_title="ğŸ“š Basit RAG Chatbot", layout="wide")

# -------------------------------
# ğŸ” .env DosyasÄ±nÄ± YÃ¼kle
# -------------------------------
load_dotenv()

# -------------------------------
# ğŸ”‘ API Key YÃ¶netimi (Streamlit Cloud + Local)
# -------------------------------
def get_api_key():
    """
    API key'i Ã¶nce Streamlit Secrets'tan almaya Ã§alÄ±ÅŸÄ±r (Streamlit Cloud iÃ§in),
    bulamazsa .env dosyasÄ±ndan alÄ±r (local development iÃ§in)
    """
    try:
        # Streamlit Cloud'da secrets kullan
        return st.secrets["GOOGLE_API_KEY"]
    except (KeyError, FileNotFoundError):
        # Local development'ta .env dosyasÄ±ndan oku
        return os.getenv("GOOGLE_API_KEY")

GOOGLE_API_KEY = get_api_key()

# BaÅŸlÄ±k
st.title("ğŸ“š Basit RAG Chatbot (EÄŸitimsel Versiyon)")

# API Key kontrolÃ¼
if not GOOGLE_API_KEY:
    st.error("âš ï¸ GOOGLE_API_KEY bulunamadÄ±! LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin veya Streamlit Cloud'da Secrets ayarlarÄ±nÄ± yapÄ±n.")
    st.info("**Streamlit Cloud kullanÄ±yorsanÄ±z:** Settings â†’ Secrets kÄ±smÄ±ndan GOOGLE_API_KEY ekleyin")
    st.info("**Local kullanÄ±yorsanÄ±z:** .env dosyasÄ±nda GOOGLE_API_KEY tanÄ±mlayÄ±n")
    st.stop()



# -------------------------------
#  PDF YÃ¼kleme
# -------------------------------
pdf = st.file_uploader("Bir PDF yÃ¼kle", type=["pdf"])
if not pdf:
    st.stop()

# -------------------------------
#  PDF â†’ Metin DÃ¶nÃ¼ÅŸÃ¼mÃ¼
# -------------------------------
pdf_reader = PdfReader(pdf)
text = ""
pages_text = []  # Her sayfanÄ±n metnini ayrÄ± tutmak iÃ§in

for idx, page in enumerate(pdf_reader.pages, 1):
    page_text = page.extract_text()
    if page_text:
        text += page_text
        pages_text.append({
            'page_num': idx,
            'text': page_text
        })

st.success(f" PDF baÅŸarÄ±yla okundu! Toplam {len(pages_text)} sayfa bulundu.")

# ğŸ”§ YardÄ±mcÄ± Fonksiyon
# -------------------------------
def get_text_content(response):
    """
    LLM (Large Language Model) yanÄ±tlarÄ±ndan yalnÄ±zca metin iÃ§eriÄŸini Ã§Ä±karÄ±r.
    - EÄŸer response bir nesne ve 'content' Ã¶zniteliÄŸine sahipse, onu dÃ¶ndÃ¼rÃ¼r.
    - EÄŸer doÄŸrudan string tipindeyse string'i dÃ¶ndÃ¼rÃ¼r.
    - DiÄŸer durumlarda response'u string'e Ã§evirip dÃ¶ndÃ¼rÃ¼r.
    """

    if hasattr(response, 'content'):
        # BazÄ± LLM yanÄ±tlarÄ±nda content alanÄ± olabilir (Ã¶rneÄŸin: OpenAI objesi)
        return response.content
    elif isinstance(response, str):
        # Response doÄŸrudan metinse
        return response
    else:
        # DiÄŸer olasÄ± tipler (Ã¶rneÄŸin dict veya Response objesi)
        return str(response)

# -------------------------------
# Text Splitting (Chunklama)
# -------------------------------
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_text(text)

# -------------------------------
# Embedding OluÅŸturma
# -------------------------------
with st.spinner("ğŸ” Embedding (vektÃ¶rleÅŸtirme) iÅŸlemi..."):
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectorstore = FAISS.from_texts(chunks, embeddings)

st.success(" VektÃ¶r veritabanÄ± hazÄ±r!")

# -------------------------------
# Soru-Cevap Zinciri (RAG)
# -------------------------------
retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", api_key=GOOGLE_API_KEY)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff"
)

# -------------------------------
#  Ã–zetleme ve Soru Ãœretme
# -------------------------------
st.subheader(" PDF Ã–zeti ve Soru Ãœretimi")

ozet_turu = st.radio(
    "Ä°ÅŸlem TÃ¼rÃ¼nÃ¼ SeÃ§:",
    [" Komple PDF Ã–zeti", " Her Sayfa AyrÄ± Ã–zet", " Sorular Ãœret"],
    horizontal=True,
    help="Komple Ã¶zet: TÃ¼m PDF'i Ã¶zetler | Sayfa sayfa: Her sayfayÄ± ayrÄ± Ã¶zetler | Sorular: Test sorularÄ± Ã¼retir"
)

if st.button(" BaÅŸlat", type="primary", use_container_width=True):

    # ========== KOMPLE PDF Ã–ZETÄ° ==========
    if ozet_turu == " Komple PDF Ã–zeti":
        with st.spinner(" PDF Ã¶zetleniyor... (RAG ile tÃ¼m PDF taranÄ±yor)"):
            summary_query = """Bu PDF'in kapsamlÄ± bir Ã¶zetini TÃ¼rkÃ§e olarak Ã§Ä±kar.
            Ana konularÄ±, Ã¶nemli noktalarÄ± ve sonuÃ§larÄ± iÃ§ersin.
            MÃ¼mkÃ¼n olduÄŸunca detaylÄ± ama Ã¶z ol."""

            response = qa_chain.run(summary_query)
            summary = get_text_content(response)

        st.success(" Komple PDF Ã–zeti HazÄ±r!")
        st.write(summary)
        st.caption(f" RAG kullanÄ±ldÄ±: Toplam {len(chunks)} chunk tarandÄ±, en alakalÄ± 4 chunk seÃ§ildi")

        # Ä°ndirme butonu
        st.download_button(
            label=" Ã–zeti Ä°ndir (TXT)",
            data=summary,
            file_name="komple_pdf_ozeti.txt",
            mime="text/plain"
        )

    # ========== HER SAYFA AYRI Ã–ZET ==========
    elif ozet_turu == " Her Sayfa AyrÄ± Ã–zet":
        st.info(f" {len(pages_text)} sayfa tek tek Ã¶zetleniyor...")

        all_summaries = []
        progress_bar = st.progress(0)

        for idx, page_data in enumerate(pages_text):
            page_num = page_data['page_num']
            page_content = page_data['text']

            # Progress gÃ¼ncelle
            progress = (idx + 1) / len(pages_text)
            progress_bar.progress(progress)

            with st.spinner(f" Sayfa {page_num}/{len(pages_text)} Ã¶zetleniyor..."):
                # Her sayfa iÃ§in LLM ile Ã¶zet
                page_summary_prompt = f"""AÅŸaÄŸÄ±daki metni TÃ¼rkÃ§e olarak Ã¶zetle.
                KÄ±sa ve Ã¶z olsun (2-3 cÃ¼mle):

                {page_content[:2000]}"""

                response = llm.invoke(page_summary_prompt)
                page_summary = get_text_content(response)

                all_summaries.append({
                    'page': page_num,
                    'summary': page_summary
                })

        progress_bar.empty()
        st.success(f" TÃ¼m {len(pages_text)} sayfa Ã¶zetlendi!")

        # Ã–zetleri gÃ¶ster
        for summary_data in all_summaries:
            with st.expander(f" Sayfa {summary_data['page']} Ã–zeti"):
                st.write(summary_data['summary'])

        # TÃ¼m Ã¶zetleri indir
        all_summaries_text = "\n\n".join([
            f"=== SAYFA {s['page']} ===\n{s['summary']}\n{'-'*60}"
            for s in all_summaries
        ])

        st.download_button(
            label=" TÃ¼m Ã–zetleri Ä°ndir (TXT)",
            data=all_summaries_text,
            file_name="sayfa_sayfa_ozetler.txt",
            mime="text/plain"
        )

    # ========== SORULAR ÃœRET ==========
    else:  # Sorular Ãœret
        with st.spinner(" Sorular oluÅŸturuluyor... (RAG ile tÃ¼m PDF taranÄ±yor)"):
            questions_query = """Bu PDF iÃ§eriÄŸine dayanarak TÃ¼rkÃ§e olarak 5-7 Ã¶nemli soru Ã¼ret.
            Sorular PDF'in farklÄ± bÃ¶lÃ¼mlerinden olsun ve kavrama dÃ¼zeyini test etsin.
            Her soruyu madde iÅŸareti ile listele."""

            response = qa_chain.run(questions_query)
            questions = get_text_content(response)

        st.success(" Sorular HazÄ±r!")
        st.write(questions)
        st.caption(f" RAG kullanÄ±ldÄ±: Toplam {len(chunks)} chunk tarandÄ±, en alakalÄ± 4 chunk seÃ§ildi")

        # Ä°ndirme butonu
        st.download_button(
            label=" SorularÄ± Ä°ndir (TXT)",
            data=questions,
            file_name="pdf_sorular.txt",
            mime="text/plain"
        )
# -------------------------------
#  KullanÄ±cÄ± Soru Sorma (RAG Chat)
# -------------------------------
st.subheader(" PDF'e Soru Sor")
user_question = st.text_input("Sorunu buraya yaz:")

if user_question:
    with st.spinner("YanÄ±t aranÄ±yor..."):
        response = qa_chain.run(user_question)
        answer = get_text_content(response)
    st.write(" **Cevap:**", answer)
    st.caption(f" RAG kullanÄ±ldÄ±: En alakalÄ± 4 chunk'tan cevap Ã¼retildi")
